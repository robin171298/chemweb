{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c63ed7e0",
   "metadata": {},
   "source": [
    "# Extract, Transform, Load process for small molecule database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf06ee43",
   "metadata": {},
   "source": [
    "### Step 1: Extract the data from PubChem.\n",
    "\n",
    "To narrow down the amount of molecules, five classes of drugs which are targeting the nervous system were selected.\n",
    "\n",
    "On https://pubchem.ncbi.nlm.nih.gov/ five queries were used: Benzodiazepines, Antidepressants, Antiepileptics, Antipsychotics, Stimulants. For all of these, a CSV was exported containing the search results with several columns of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70756f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "import requests\n",
    "from time import sleep\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "from pathlib import Path\n",
    "import mysql.connector\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b60fc4",
   "metadata": {},
   "source": [
    "To add a bit more information, the \"requests\" library was used. The csv files were enriched with additional data (Mechanism of action and main medical use)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e54664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input CSV files to process (one enriched output per file)\n",
    "FILES = [\n",
    "    \"PubChem_compound_text_Stimulants.csv\",\n",
    "    \"PubChem_compound_text_Antidepressants.csv\",\n",
    "    \"PubChem_compound_text_Antiepileptics.csv\",\n",
    "    \"PubChem_compound_text_Antipsychotics.csv\",\n",
    "    \"PubChem_compound_text_Benzodiazepines_APPROVED.csv\",\n",
    "]\n",
    "\n",
    "# Base directory containing all CSV files\n",
    "BASE_DIR = Path(\"nervous_system_drugs\")\n",
    "\n",
    "# Column holding PubChem Compound IDs\n",
    "CID_COLUMN = \"Compound_CID\"\n",
    "\n",
    "# Optional processing limit (None = process all rows)\n",
    "MAX_ROWS = None\n",
    "\n",
    "# Delay between API requests to avoid rate-limiting\n",
    "SLEEP_TIME = 0.2\n",
    "\n",
    "\n",
    "def get_pubchem_text(cid):\n",
    "    \"\"\"Fetch mechanism of action and main medical use from PubChem.\"\"\"\n",
    "    url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{cid}/JSON/\"\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=15)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error fetching/parsing CID {cid}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "    mech = None\n",
    "    use = None\n",
    "\n",
    "    # Recursively traverse PubChem's nested section structure\n",
    "    def walk_sections(sections):\n",
    "        nonlocal mech, use\n",
    "        for sec in sections:\n",
    "            heading = sec.get(\"TOCHeading\", \"\").lower()\n",
    "\n",
    "            for info in sec.get(\"Information\", []):\n",
    "                text_chunks = info.get(\"Value\", {}).get(\"StringWithMarkup\", [])\n",
    "                if not text_chunks:\n",
    "                    continue\n",
    "\n",
    "                text = text_chunks[0].get(\"String\", \"\").strip()\n",
    "                if not text:\n",
    "                    continue\n",
    "\n",
    "                # Heuristic matching based on section headings\n",
    "                if (\"mechanism of action\" in heading or\n",
    "                    (\"pharmacology\" in heading and mech is None)):\n",
    "                    mech = mech or text\n",
    "\n",
    "                if (\"indication\" in heading or\n",
    "                    \"drug indication\" in heading or\n",
    "                    \"indications and usage\" in heading or\n",
    "                    (\"therapeutic uses\" in heading and use is None) or\n",
    "                    (\"clinical information\" in heading and use is None)):\n",
    "                    use = use or text\n",
    "\n",
    "            # Recurse into subsections\n",
    "            if \"Section\" in sec:\n",
    "                walk_sections(sec[\"Section\"])\n",
    "\n",
    "    try:\n",
    "        walk_sections(data[\"Record\"][\"Section\"])\n",
    "    except KeyError:\n",
    "        # Some CIDs do not follow the standard PubChem structure\n",
    "        pass\n",
    "\n",
    "    return mech, use\n",
    "\n",
    "\n",
    "def enrich_csv(input_csv: Path):\n",
    "    # Output file name: *_ENRICHED.csv\n",
    "    output_csv = input_csv.with_name(input_csv.stem + \"_ENRICHED.csv\")\n",
    "    print(f\"\\n=== Processing {input_csv.name} ===\")\n",
    "\n",
    "    df = pd.read_csv(input_csv)\n",
    "\n",
    "    # Columns to be populated from PubChem\n",
    "    df[\"Mechanism_of_Action\"] = None\n",
    "    df[\"Main_Medical_Use\"] = None\n",
    "\n",
    "    # Cache avoids repeated API calls for duplicate CIDs\n",
    "    cache = {}\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        if MAX_ROWS and i >= MAX_ROWS:\n",
    "            print(f\"Reached limit of {MAX_ROWS} rows.\")\n",
    "            break\n",
    "\n",
    "        cid = row.get(CID_COLUMN)\n",
    "        if pd.isna(cid):\n",
    "            continue\n",
    "\n",
    "        if cid not in cache:\n",
    "            print(f\"CID {cid} ({i+1})\")\n",
    "            cache[cid] = get_pubchem_text(cid)\n",
    "            sleep(SLEEP_TIME)\n",
    "\n",
    "        df.at[i, \"Mechanism_of_Action\"], df.at[i, \"Main_Medical_Use\"] = cache[cid]\n",
    "\n",
    "    df.iloc[:MAX_ROWS].to_csv(output_csv, index=False)\n",
    "    print(f\"Saved â†’ {output_csv.name}\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Process all configured CSV files\n",
    "    for fname in FILES:\n",
    "        path = BASE_DIR / fname\n",
    "        if path.exists():\n",
    "            enrich_csv(path)\n",
    "        else:\n",
    "            print(f\"[!] File not found: {path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676f0482",
   "metadata": {},
   "source": [
    "Look at one example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1bb34ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compound_CID                                                                       2118\n",
       "Name                                                                         Alprazolam\n",
       "Synonyms                              alprazolam|Xanax|28981-97-7|Niravam|Solanax|Tr...\n",
       "Molecular_Weight                                                                  308.8\n",
       "Molecular_Formula                                                            C17H13ClN4\n",
       "Polar_Area                                                                         43.1\n",
       "Complexity                                                                        434.0\n",
       "XLogP                                                                               2.1\n",
       "Heavy_Atom_Count                                                                     22\n",
       "H-Bond_Donor_Count                                                                    0\n",
       "H-Bond_Acceptor_Count                                                                 3\n",
       "Rotatable_Bond_Count                                                                  1\n",
       "InChI                                 InChI=1S/C17H13ClN4/c1-11-20-21-16-10-19-17(12...\n",
       "SMILES                                   CC1=NN=C2N1C3=C(C=C(C=C3)Cl)C(=NC2)C4=CC=CC=C4\n",
       "InChIKey                                                    VREFGVBLTWBCJP-UHFFFAOYSA-N\n",
       "IUPAC_Name                            8-chloro-1-methyl-6-phenyl-4H-[1,2,4]triazolo[...\n",
       "Exact_Mass                                                                   308.082874\n",
       "Monoisotopic_Mass                                                            308.082874\n",
       "Charge                                                                                0\n",
       "Covalent_Unit_Count                                                                   1\n",
       "Isotopic_Atom_Count                                                                   0\n",
       "Total_Atom_Stereo_Count                                                               0\n",
       "Defined_Atom_Stereo_Count                                                             0\n",
       "Undefined_Atom_Stereo_Count                                                           0\n",
       "Total_Bond_Stereo_Count                                                               0\n",
       "Defined_Bond_Stereo_Count                                                             0\n",
       "Undefined_Bond_Stereo_Count                                                           0\n",
       "Linked_PubChem_Literature_Count                                                    8481\n",
       "Linked_PubChem_Patent_Count                                                       18236\n",
       "Linked_PubChem_Patent_Family_Count                                                 6227\n",
       "MeSH_Headings                                                                Alprazolam\n",
       "Annotation_Content                    Biological Test Results|Interactions and Pathw...\n",
       "Annotation_Type_Count                                                                17\n",
       "Linked_BioAssays                      485|568|583|598|602|618|620|629|630|631|633|63...\n",
       "Create_Date                                                                    20050325\n",
       "Data_Source                           A&J Pharmtech CO., LTD.|ABI Chem|Acorn PharmaT...\n",
       "Data_Source_Category                  Chemical Vendors|Curation Efforts|Governmental...\n",
       "Tagged_by_PubChem                     C78272 - Agent Affecting Nervous System > C281...\n",
       "Mechanism_of_Action                   Neurotransmission relies on excitatory and inh...\n",
       "Main_Medical_Use                      Alprazolam is indicated for the acute treatmen...\n",
       "drug_class                                                               benzodiazepine\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benzodiazepines_enriched = pd.read_csv(r\"nervous_system_drugs/PubChem_compound_text_Benzodiazepines_ENRICHED.csv\")\n",
    "\n",
    "benzodiazepines_enriched.iloc[2, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea1160",
   "metadata": {},
   "source": [
    "Add a new column to all of the csv files which labels the class of the molecule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e95b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: nervous_system_drugs/PubChem_compound_text_Benzodiazepines_ENRICHED.csv\n",
      "âœ… Added drug_class = 'benzodiazepine' to nervous_system_drugs/PubChem_compound_text_Benzodiazepines_ENRICHED.csv\n",
      "\n",
      "ðŸŽ‰ All files processed.\n"
     ]
    }
   ],
   "source": [
    "# Map each enriched CSV file to its corresponding drug class label\n",
    "FILES_AND_CLASSES = {\n",
    "    \"nervous_system_drugs/PubChem_compound_text_Antidepressants_ENRICHED.csv\": \"antidepressant\",\n",
    "    \"nervous_system_drugs/PubChem_compound_text_Antiepileptics_ENRICHED.csv\": \"antiepileptic\",\n",
    "    \"nervous_system_drugs/PubChem_compound_text_Antipsychotics_ENRICHED.csv\": \"antipsychotic\",\n",
    "    \"nervous_system_drugs/PubChem_compound_text_Benzodiazepines_ENRICHED.csv\": \"benzodiazepine\",\n",
    "    \"nervous_system_drugs/PubChem_compound_text_Stimulants_ENRICHED.csv\": \"stimulant\",\n",
    "}\n",
    "\n",
    "# Iterate over all files and apply the corresponding drug class\n",
    "for filename, drug_class in FILES_AND_CLASSES.items():\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"[!] File not found: {filename}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing: {filename}\")\n",
    "\n",
    "    df = pd.read_csv(filename)\n",
    "\n",
    "    # Add or overwrite a uniform class label for all rows\n",
    "    df[\"drug_class\"] = drug_class\n",
    "\n",
    "    # Write changes back to the same file\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "    print(f\"âœ… Added drug_class = '{drug_class}' to {filename}\")\n",
    "\n",
    "print(\"\\nAll files processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca06731",
   "metadata": {},
   "source": [
    "Also, the benzodiazepine dataset had to be filtered, because it was pretty big with 300'000 entries (containing not only \"real\" benzodiazepines but also structurally related compounds).\n",
    "For this, a list containing the approved benzodiazepines was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9bf349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\robin\\AppData\\Local\\Temp\\ipykernel_22292\\1184772841.py:106: DtypeWarning: Columns (2,30,31,33,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(INPUT_CSV)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in original file: 292056\n",
      "Rows matching approved benzodiazepines: 40\n",
      "Saved approved benzodiazepines to: nervous_system_drugs/PubChem_compound_text_Benzodiazepines_APPROVED.csv\n"
     ]
    }
   ],
   "source": [
    "INPUT_CSV = r\"nervous_system_drugs/PubChem_compound_text_Benzodiazepines.csv\"\n",
    "OUTPUT_CSV = r\"nervous_system_drugs/PubChem_compound_text_Benzodiazepines_APPROVED.csv\"\n",
    "\n",
    "# List of commonly used / approved benzodiazepines (EU/US, etc.)\n",
    "APPROVED_BENZOS = {\n",
    "    # ===== CORE GLOBAL BENZODIAZEPINES =====\n",
    "    \"alprazolam\",\n",
    "    \"bromazepam\",\n",
    "    \"chlordiazepoxide\",\n",
    "    \"clobazam\",\n",
    "    \"clonazepam\",\n",
    "    \"clorazepate\",\n",
    "    \"diazepam\",\n",
    "    \"estazolam\",\n",
    "    \"flunitrazepam\",\n",
    "    \"flurazepam\",\n",
    "    \"halazepam\",\n",
    "    \"lorazepam\",\n",
    "    \"lormetazepam\",\n",
    "    \"midazolam\",\n",
    "    \"nitrazepam\",\n",
    "    \"oxazepam\",\n",
    "    \"prazepam\",\n",
    "    \"quazepam\",\n",
    "    \"temazepam\",\n",
    "    \"triazolam\",\n",
    "\n",
    "    # ===== ACTIVE METABOLITES / PRODRUGS =====\n",
    "    \"nordazepam\",\n",
    "    \"desmethyldiazepam\",\n",
    "    \"desalkylflurazepam\",\n",
    "    \"avizafone\",\n",
    "    \"rilmazafone\",\n",
    "    \"fosazepam\",\n",
    "\n",
    "    # ===== THIENODIAZEPINES (REAL MEDICAL USE) =====\n",
    "    \"etizolam\",\n",
    "    \"brotizolam\",\n",
    "    \"clotiazepam\",\n",
    "\n",
    "    # ===== REGIONAL / JAPAN / EU ONLY =====\n",
    "    \"mexazolam\",\n",
    "    \"pinazepam\",\n",
    "    \"ketazolam\",\n",
    "    \"loprazolam\",\n",
    "    \"cinazepam\",\n",
    "    \"medazepam\",\n",
    "    \"camazepam\",\n",
    "    \"iprazepam\",\n",
    "    \"metaclazepam\",\n",
    "    \"nimetazepam\",\n",
    "    \"pivoxazepam\",\n",
    "    \"bentazepam\",\n",
    "\n",
    "    # ===== DISCONTINUED BUT HISTORICALLY PRESCRIBED =====\n",
    "    \"arfenda\",\n",
    "    \"fletazepam\",\n",
    "    \"flutoprazepam\",\n",
    "    \"meclonazepam\",\n",
    "    \"tetrazepam\",\n",
    "    \"safrazepam\",\n",
    "    \"suriclone\",\n",
    "\n",
    "    # ===== RARE / HOSPITAL-ONLY / LEGACY =====\n",
    "    \"remimazolam\",\n",
    "    \"tolazepam\",\n",
    "    \"ro09-9212\",\n",
    "    \"ro15-1788\",       # flumazenil (antidote, still a benzodiazepine core)\n",
    "    \"flutazolam\",\n",
    "    \"adaline\",\n",
    "    \"devazepide\",\n",
    "\n",
    "    # ===== INACTIVE / STRUCTURAL BENZOS WITH MEDICAL MENTIONS =====\n",
    "    \"bifemelane\",\n",
    "    \"pazinaclone\",\n",
    "    \"zometapine\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def normalize_name(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalize a compound name for comparison:\n",
    "    - lowercase\n",
    "    - strip whitespace\n",
    "    - cut off anything after '[' or '(' (e.g. 'Diazepam [INN]' -> 'diazepam')\n",
    "    \"\"\"\n",
    "    if pd.isna(name):\n",
    "        return \"\"\n",
    "    name = str(name).lower().strip()\n",
    "    for sep in [\"[\", \"(\"]:\n",
    "        if sep in name:\n",
    "            name = name.split(sep)[0]\n",
    "    return name.strip()\n",
    "\n",
    "\n",
    "def main():\n",
    "    if not os.path.exists(INPUT_CSV):\n",
    "        raise FileNotFoundError(f\"Input file not found: {INPUT_CSV}\")\n",
    "\n",
    "    df = pd.read_csv(INPUT_CSV)\n",
    "\n",
    "    if \"Name\" not in df.columns:\n",
    "        raise KeyError(\"Column 'Name' not found in CSV\")\n",
    "\n",
    "    # Create normalized name column\n",
    "    df[\"name_norm\"] = df[\"Name\"].apply(normalize_name)\n",
    "\n",
    "    # Filter to only rows whose normalized name is in our approved list\n",
    "    mask = df[\"name_norm\"].isin(APPROVED_BENZOS)\n",
    "    df_approved = df[mask].copy()\n",
    "\n",
    "    # Drop helper column before saving\n",
    "    df_approved.drop(columns=[\"name_norm\"], inplace=True)\n",
    "\n",
    "    print(f\"Total rows in original file: {len(df)}\")\n",
    "    print(f\"Rows matching approved benzodiazepines: {len(df_approved)}\")\n",
    "\n",
    "    df_approved.to_csv(OUTPUT_CSV, index=False)\n",
    "    print(f\"Saved approved benzodiazepines to: {OUTPUT_CSV}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c567cfeb",
   "metadata": {},
   "source": [
    "### Step 2: Create a fitting database which contains the same columns in a table like in the csv files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b99bf27",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "CREATE DATABASE IF NOT EXISTS chemdb;\n",
    "USE chemdb;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4240afa1",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "CREATE TABLE nervous_system_drugs (\n",
    "    id                              INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    Compound_CID                    INT,\n",
    "    Name                            VARCHAR(255),\n",
    "    Synonyms                        TEXT,\n",
    "    Molecular_Weight                DECIMAL(12,4),\n",
    "    Molecular_Formula               VARCHAR(50),\n",
    "    Polar_Area                      DECIMAL(12,4),\n",
    "    Complexity                      DECIMAL(12,4),\n",
    "    XLogP                           DECIMAL(12,4),\n",
    "    Heavy_Atom_Count                INT,\n",
    "    `H-Bond_Donor_Count`            INT,\n",
    "    `H-Bond_Acceptor_Count`         INT,\n",
    "    Rotatable_Bond_Count            INT,\n",
    "    InChI                           TEXT,\n",
    "    SMILES                          TEXT,\n",
    "    InChIKey                        VARCHAR(255),\n",
    "    IUPAC_Name                      TEXT,\n",
    "    Exact_Mass                      DECIMAL(12,6),\n",
    "    Monoisotopic_Mass               DECIMAL(12,6),\n",
    "    Charge                          INT,\n",
    "    Covalent_Unit_Count             INT,\n",
    "    Isotopic_Atom_Count             INT,\n",
    "    Total_Atom_Stereo_Count         INT,\n",
    "    Defined_Atom_Stereo_Count       INT,\n",
    "    Undefined_Atom_Stereo_Count     INT,\n",
    "    Total_Bond_Stereo_Count         INT,\n",
    "    Defined_Bond_Stereo_Count       INT,\n",
    "    Undefined_Bond_Stereo_Count     INT,\n",
    "    Linked_PubChem_Literature_Count INT,\n",
    "    Linked_PubChem_Patent_Count     INT,\n",
    "    Linked_PubChem_Patent_Family_Count INT,\n",
    "    MeSH_Headings                   TEXT,\n",
    "    Annotation_Content              TEXT,\n",
    "    Annotation_Type_Count           INT,\n",
    "    Linked_BioAssays                TEXT,\n",
    "    Create_Date                     VARCHAR(20),   -- or DATE if you later convert YYYYMMDD\n",
    "    Data_Source                     TEXT,\n",
    "    Data_Source_Category            TEXT,\n",
    "    Tagged_by_PubChem               TEXT,\n",
    "    Mechanism_of_Action             TEXT,\n",
    "    Main_Medical_Use                TEXT,\n",
    "    drug_class                      VARCHAR(50)    -- ðŸ‘ˆ added for your 5 groups\n",
    ");\n",
    "\n",
    "-- Optional indexes (nice for performance)\n",
    "CREATE INDEX idx_cid ON nervous_system_drugs (Compound_CID);\n",
    "CREATE INDEX idx_drug_class ON nervous_system_drugs (drug_class);\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73251b29",
   "metadata": {},
   "source": [
    "### Step 3: Import the csv files into the chemdb database using the import wizard in mysql workbench.\n",
    "\n",
    "Somehow it didnt work with the benzodiazepine dataset. As an alternative way, the code below was used (with mysql connector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f8ae41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Benzodiazepines imported successfully (NaN â†’ NULL).\n"
     ]
    }
   ],
   "source": [
    "# Path to the enriched CSV file to be imported\n",
    "CSV_FILE = r\"C:/Users/robin/Dropbox/Robin_Desktop/3_Semester/Databases/ETL_Life_Science_Databases/nervous_system_drugs/Import_with_wizard_to_database/PubChem_compound_text_Benzodiazepines_ENRICHED.csv\"\n",
    "\n",
    "# Connect to the MySQL database\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Labor.2024\",\n",
    "    database=\"chemdb\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Parameterized INSERT statement matching the table schema\n",
    "insert_sql = \"\"\"\n",
    "INSERT INTO nervous_system_drugs (\n",
    "    Compound_CID, Name, Synonyms, Molecular_Weight, Molecular_Formula,\n",
    "    Polar_Area, Complexity, XLogP, Heavy_Atom_Count,\n",
    "    `H-Bond_Donor_Count`, `H-Bond_Acceptor_Count`, Rotatable_Bond_Count,\n",
    "    InChI, SMILES, InChIKey, IUPAC_Name, Exact_Mass, Monoisotopic_Mass,\n",
    "    Charge, Covalent_Unit_Count, Isotopic_Atom_Count,\n",
    "    Total_Atom_Stereo_Count, Defined_Atom_Stereo_Count,\n",
    "    Undefined_Atom_Stereo_Count, Total_Bond_Stereo_Count,\n",
    "    Defined_Bond_Stereo_Count, Undefined_Bond_Stereo_Count,\n",
    "    Linked_PubChem_Literature_Count, Linked_PubChem_Patent_Count,\n",
    "    Linked_PubChem_Patent_Family_Count, MeSH_Headings,\n",
    "    Annotation_Content, Annotation_Type_Count, Linked_BioAssays,\n",
    "    Create_Date, Data_Source, Data_Source_Category, Tagged_by_PubChem,\n",
    "    Mechanism_of_Action, Main_Medical_Use, drug_class\n",
    ")\n",
    "VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "\"\"\"\n",
    "\n",
    "# Insert each row, converting pandas NaN values to SQL NULL\n",
    "for _, row in df.iterrows():\n",
    "    values = []\n",
    "    for v in row:\n",
    "        if pd.isna(v) or (isinstance(v, float) and math.isnan(v)):\n",
    "            values.append(None)\n",
    "        else:\n",
    "            values.append(v)\n",
    "\n",
    "    cursor.execute(insert_sql, tuple(values))\n",
    "\n",
    "# Persist changes and cleanly close the connection\n",
    "conn.commit()\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "print(\"Benzodiazepines imported successfully (NaN â†’ NULL).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0796015f",
   "metadata": {},
   "source": [
    "### Step 4: Get additional synonyms from other sources (Chembl and Wikidata)\n",
    "\n",
    "Because this takes long to run, only every 10th entry from the files is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f1e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input CSV files containing compounds to enrich with synonyms\n",
    "CSV_FILES = [\n",
    "    \"PubChem_compound_text_Antidepressants_ENRICHED.csv\",\n",
    "    \"PubChem_compound_text_Antiepileptics_ENRICHED.csv\",\n",
    "    \"PubChem_compound_text_Antipsychotics_ENRICHED.csv\",\n",
    "    \"PubChem_compound_text_Benzodiazepines_ENRICHED.csv\",\n",
    "    \"PubChem_compound_text_Stimulants_ENRICHED.csv\"\n",
    "]\n",
    "\n",
    "# Column used to link compounds across databases\n",
    "INCHIKEY_COLUMN = \"InChIKey\"\n",
    "\n",
    "# Output file collecting all retrieved synonyms\n",
    "OUTPUT_CSV = \"synonyms_from_chembl_wikidata.csv\"\n",
    "\n",
    "# Optional delay to avoid stressing external APIs\n",
    "SLEEP_BETWEEN_REQUESTS = 0\n",
    "\n",
    "\n",
    "# API endpoints\n",
    "CHEMBL_BASE = \"https://www.ebi.ac.uk/chembl/api/data/molecule/{inchikey}.json\"\n",
    "WIKIDATA_SPARQL = \"https://query.wikidata.org/sparql\"\n",
    "\n",
    "\n",
    "def load_inchikeys_from_csv(files, inchikey_col):\n",
    "    \"\"\"\n",
    "    Load unique InChIKeys from multiple CSV files.\n",
    "    Only every 10th row per file is considered to reduce runtime.\n",
    "    \"\"\"\n",
    "    inchikeys = set()\n",
    "\n",
    "    for filename in files:\n",
    "        path = Path(filename)\n",
    "        if not path.exists():\n",
    "            print(f\"Warning: File {filename} not found â€“ skipping.\")\n",
    "            continue\n",
    "\n",
    "        with open(path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "            reader = csv.DictReader(f)\n",
    "\n",
    "            if inchikey_col not in reader.fieldnames:\n",
    "                print(\n",
    "                    f\"Warning: Column '{inchikey_col}' not found in {filename}. \"\n",
    "                    f\"Found columns: {reader.fieldnames}\"\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            row_counter = 0\n",
    "            for row in reader:\n",
    "                row_counter += 1\n",
    "\n",
    "                # Take only every 10th entry to limit API calls\n",
    "                if row_counter % 10 != 0:\n",
    "                    continue\n",
    "\n",
    "                ik = (row.get(inchikey_col) or \"\").strip()\n",
    "                if ik:\n",
    "                    inchikeys.add(ik)\n",
    "\n",
    "    print(f\"Loaded {len(inchikeys)} unique InChIKeys from CSV files.\")\n",
    "    return sorted(inchikeys)\n",
    "\n",
    "\n",
    "def get_chembl_synonyms_for_inchikey(inchikey: str):\n",
    "    \"\"\"Fetch synonyms for a compound from ChEMBL using its InChIKey.\"\"\"\n",
    "    url = CHEMBL_BASE.format(inchikey=inchikey)\n",
    "\n",
    "    try:\n",
    "        r = requests.get(url, timeout=15)\n",
    "    except Exception as e:\n",
    "        print(f\"  [ChEMBL] Network error for {inchikey}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # 404 means no ChEMBL entry for this InChIKey (normal case)\n",
    "    if r.status_code != 200:\n",
    "        if r.status_code != 404:\n",
    "            print(f\"  [ChEMBL] HTTP {r.status_code} for {inchikey}\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = r.json()\n",
    "    except Exception as e:\n",
    "        print(f\"  [ChEMBL] JSON parsing error for {inchikey}: {e}\")\n",
    "        return []\n",
    "\n",
    "    syns = []\n",
    "    for entry in data.get(\"molecule_synonyms\", []):\n",
    "        s = entry.get(\"synonyms\")\n",
    "        if s:\n",
    "            syns.append(s.strip())\n",
    "\n",
    "    return syns\n",
    "\n",
    "\n",
    "def get_wikidata_synonyms_for_inchikey(inchikey: str):\n",
    "    \"\"\"\n",
    "    Fetch synonyms from Wikidata via SPARQL using InChIKey (P235).\n",
    "    Retrieves both the main label and alternative labels.\n",
    "    \"\"\"\n",
    "    query = f\"\"\"\n",
    "    SELECT ?itemLabel ?altLabel WHERE {{\n",
    "      ?item wdt:P235 \"{inchikey}\".\n",
    "      OPTIONAL {{ ?item skos:altLabel ?altLabel. }}\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en,de\". }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    headers = {\n",
    "        \"Accept\": \"application/sparql-results+json\",\n",
    "        # Required by Wikidata for polite API usage\n",
    "        \"User-Agent\": \"SynonymFetcher/1.0 (contact: your_email@example.com)\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        r = requests.get(\n",
    "            WIKIDATA_SPARQL,\n",
    "            params={\"query\": query},\n",
    "            headers=headers,\n",
    "            timeout=20\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"  [Wikidata] Network error for {inchikey}: {e}\")\n",
    "        return []\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        print(f\"  [Wikidata] HTTP {r.status_code} for {inchikey}\")\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        data = r.json()\n",
    "    except Exception as e:\n",
    "        print(f\"  [Wikidata] JSON parsing error for {inchikey}: {e}\")\n",
    "        return []\n",
    "\n",
    "    syns = set()\n",
    "    for row in data.get(\"results\", {}).get(\"bindings\", []):\n",
    "        label = row.get(\"itemLabel\", {}).get(\"value\")\n",
    "        alt = row.get(\"altLabel\", {}).get(\"value\")\n",
    "\n",
    "        if label:\n",
    "            syns.add(label.strip())\n",
    "        if alt:\n",
    "            syns.add(alt.strip())\n",
    "\n",
    "    return sorted(syns)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Collect InChIKeys across all input files\n",
    "    inchikeys = load_inchikeys_from_csv(CSV_FILES, INCHIKEY_COLUMN)\n",
    "\n",
    "    with open(OUTPUT_CSV, \"w\", newline=\"\", encoding=\"utf-8\") as f_out:\n",
    "        writer = csv.writer(f_out)\n",
    "        writer.writerow([\"inchikey\", \"source\", \"synonym\"])\n",
    "\n",
    "        for idx, ik in enumerate(inchikeys, start=1):\n",
    "            print(f\"[{idx}/{len(inchikeys)}] Processing {ik} ...\")\n",
    "\n",
    "            # ChEMBL synonyms\n",
    "            chembl_syns = get_chembl_synonyms_for_inchikey(ik)\n",
    "            print(f\"  ChEMBL: {len(chembl_syns)} synonyms\")\n",
    "            for s in chembl_syns:\n",
    "                writer.writerow([ik, \"ChEMBL\", s])\n",
    "\n",
    "            # Wikidata synonyms\n",
    "            wikidata_syns = get_wikidata_synonyms_for_inchikey(ik)\n",
    "            print(f\"  Wikidata: {len(wikidata_syns)} synonyms\")\n",
    "            for s in wikidata_syns:\n",
    "                writer.writerow([ik, \"Wikidata\", s])\n",
    "\n",
    "            # Flush to disk to avoid data loss during long runs\n",
    "            f_out.flush()\n",
    "\n",
    "            time.sleep(SLEEP_BETWEEN_REQUESTS)\n",
    "\n",
    "    print(f\"Done! Synonyms saved to: {OUTPUT_CSV}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf5e2db",
   "metadata": {},
   "source": [
    "### Step 5: Import the additional synonyms into the database after creating a new table\n",
    "\n",
    "Create new synonyms table in MySQL Database:\n",
    "\n",
    "```\n",
    "CREATE TABLE synonyms (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    inchikey VARCHAR(27) NOT NULL,\n",
    "    source VARCHAR(50) NOT NULL,\n",
    "    synonym TEXT NOT NULL\n",
    ");\n",
    "```\n",
    "\n",
    "Afterwards, load the new synonyms into the table using python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358cccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"synonyms_from_chembl_wikidata_utf8.csv\")\n",
    "\n",
    "# Clean column names (remove whitespace and potential UTF-8 BOM)\n",
    "df.columns = [c.strip().lstrip(\"\\ufeff\") for c in df.columns]\n",
    "\n",
    "# Normalize InChIKey column name if needed\n",
    "if \"inchikey\" not in df.columns and \"InChIKey\" in df.columns:\n",
    "    df = df.rename(columns={\"InChIKey\": \"inchikey\"})\n",
    "\n",
    "# Keep only required columns and drop incomplete rows\n",
    "df = df[[\"inchikey\", \"source\", \"synonym\"]].dropna()\n",
    "\n",
    "# Convert DataFrame to a list of tuples for executemany()\n",
    "rows = list(df.itertuples(index=False, name=None))\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"root\",\n",
    "    password=\"Labor.2024\",\n",
    "    database=\"chemdb\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.executemany(\n",
    "    \"INSERT INTO synonyms (inchikey, source, synonym) VALUES (%s, %s, %s)\",\n",
    "    rows\n",
    ")\n",
    "\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(f\"Import completed. Rows attempted to insert: {len(rows)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
